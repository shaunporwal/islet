[{"path":"http://www.shaunporwal.com/islet/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 islet authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"http://www.shaunporwal.com/islet/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Shaun P. Porwal. Author, maintainer.","code":""},{"path":"http://www.shaunporwal.com/islet/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Porwal S (2025). islet: Provides Data Pipelining Functions. R package version 0.2.0, http://www.shaunporwal.com/islet/.","code":"@Manual{,   title = {islet: Provides Data Pipelining Functions},   author = {Shaun P. Porwal},   year = {2025},   note = {R package version 0.2.0},   url = {http://www.shaunporwal.com/islet/}, }"},{"path":"http://www.shaunporwal.com/islet/index.html","id":"islet","dir":"","previous_headings":"","what":"Provides Data Pipelining Functions","title":"Provides Data Pipelining Functions","text":"Personal R functions.","code":""},{"path":"http://www.shaunporwal.com/islet/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Provides Data Pipelining Functions","text":"can install development version islet GitHub :","code":"# install.packages(\"devtools\") devtools::install_github(\"shaunporwal/islet\")"},{"path":"http://www.shaunporwal.com/islet/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Provides Data Pipelining Functions","text":"basic example shows solve common problem: ’ll still need render README.Rmd regularly, keep README.md --date. devtools::build_readme() handy . also use GitHub Actions re-render README.Rmd every time push. example workflow can found : https://github.com/r-lib/actions/tree/v1/examples. case, don’t forget commit push resulting figure files, display GitHub CRAN.","code":"library(islet) # Simple Example, Default '&' Border islet::make_banner(str_to_banner = 'analyze column from dataframe') #> #&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& #> #&&  analyze column from dataframe  && #> #&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& # Output Saved to Clipboard, Can Cmd+v or Ctrl+v to directly paste banner # New Banner Border Example islet::make_banner(str_to_banner = 'analyze column from dataframe',                    banner_chr = '+') #> #+++++++++++++++++++++++++++++++++++++ #> #++  analyze column from dataframe  ++ #> #+++++++++++++++++++++++++++++++++++++"},{"path":"http://www.shaunporwal.com/islet/reference/check_duplicates.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if there are duplicate rows in a dataframe based on grouped columns — check_duplicates","title":"Check if there are duplicate rows in a dataframe based on grouped columns — check_duplicates","text":"Check duplicate rows dataframe based grouped columns","code":""},{"path":"http://www.shaunporwal.com/islet/reference/check_duplicates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if there are duplicate rows in a dataframe based on grouped columns — check_duplicates","text":"","code":"check_duplicates(data_df, group_by_vars = NULL, print_dups = TRUE)"},{"path":"http://www.shaunporwal.com/islet/reference/check_duplicates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if there are duplicate rows in a dataframe based on grouped columns — check_duplicates","text":"data_df Dataframe checked duplicates group_by_vars string vector strings column name(s) group asserting uniqueness print_dups boolean argument, TRUE, allow function display duplicate rows","code":""},{"path":"http://www.shaunporwal.com/islet/reference/check_duplicates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if there are duplicate rows in a dataframe based on grouped columns — check_duplicates","text":"Duplicate rows, general variable/column groupings","code":""},{"path":"http://www.shaunporwal.com/islet/reference/check_duplicates.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check if there are duplicate rows in a dataframe based on grouped columns — check_duplicates","text":"","code":"# Load the dplyr package library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union  # Create a sample data frame data_df <- data.frame(   ID = c(1, 1, 2, 3, 4),   Age = c(25, 25, 30, 40, 50),   Income = c(50000, 50000, 60000, 70000, 80000) )  # Call the function to check for duplicates in the entire data frame check_duplicates(data_df) #> [1] \"Duplicates Exist:\" #>   ID Age Income #> 1  1  25  50000  # Call the function to check for duplicates within the \"ID\" column check_duplicates(data_df, group_by_vars = \"ID\") #> [1] \"Duplicates Exist:\" #>   ID Age Income #> 1  1  25  50000  # Call the function to check for duplicates within the \"ID\" and \"Age\" columns check_duplicates(data_df, group_by_vars = c(\"ID\", \"Age\")) #> [1] \"Duplicates Exist:\" #>   ID Age Income #> 1  1  25  50000"},{"path":"http://www.shaunporwal.com/islet/reference/compare_clean_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare and Analyze Clean Data — compare_clean_data","title":"Compare and Analyze Clean Data — compare_clean_data","text":"function compares two clean datasets, filters based specified date range, generates outputs numeric, factor, character, binary, date, data types. results saved output directory, optional views data can displayed saved.","code":""},{"path":"http://www.shaunporwal.com/islet/reference/compare_clean_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare and Analyze Clean Data — compare_clean_data","text":"","code":"compare_clean_data(   df_old_path,   df_new_path,   output_dir,   final_vars_set,   date_col,   limit_to_same_date = TRUE,   show_views = FALSE,   save_views = FALSE )"},{"path":"http://www.shaunporwal.com/islet/reference/compare_clean_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare and Analyze Clean Data — compare_clean_data","text":"df_old_path Character. Path old dataset file (e.g., CSV file). df_new_path Character. Path new dataset file (e.g., CSV file). output_dir Character. Path directory output files saved. final_vars_set Character vector. List variable names include comparison. date_col Character. Name column datasets representing date. function uses column filter rows based date range. limit_to_same_date Logical. Whether filter new dataset match date range old dataset (default: TRUE). show_views Logical. Whether display data views RStudio Viewer (default: FALSE). save_views Logical. Whether save views dataframes disk (default: FALSE).","code":""},{"path":"http://www.shaunporwal.com/islet/reference/compare_clean_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare and Analyze Clean Data — compare_clean_data","text":"list dataframes containing comparison results. Dataframes include numeric, factor, character, binary, date, derived datasets. Entries missing data omitted. function also saves CSV files comparison results specified output directory. save_views TRUE, views dataframes saved additional files output directory.","code":""},{"path":"http://www.shaunporwal.com/islet/reference/compare_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare Dataframes — compare_df","title":"Compare Dataframes — compare_df","text":"Compares two datasets, summarizing numeric, factor, character, binary, date, group-specific fields. Handles comparisons without new dataset.","code":""},{"path":"http://www.shaunporwal.com/islet/reference/compare_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare Dataframes — compare_df","text":"","code":"compare_df(   old_data,   new_data = NULL,   suffix_term = \"\",   ind_outcomes = c(\"\"),   group_col,   add_years = FALSE )"},{"path":"http://www.shaunporwal.com/islet/reference/compare_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare Dataframes — compare_df","text":"old_data Dataframe. old dataset compare. new_data Dataframe. new dataset compare. NULL, old dataset analyzed. suffix_term Character. Suffix append parsed column names (default: \"\"). ind_outcomes Character vector. Individual outcomes summarize (default: \"\"). group_col Character. Column name representing grouping variable (required). add_years Logical. Whether include year-based summaries (default: FALSE).","code":""},{"path":"http://www.shaunporwal.com/islet/reference/compare_df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare Dataframes — compare_df","text":"list dataframes containing comparison results: numeric_join Merged numeric fields. factor_join Merged factor fields. char_join Merged character fields. bin_join Merged binary fields. date_join Merged date fields. group_join Merged group-specific summaries.","code":""},{"path":"http://www.shaunporwal.com/islet/reference/from_win_to_mac.html","id":null,"dir":"Reference","previous_headings":"","what":"Title — from_win_to_mac","title":"Title — from_win_to_mac","text":"Title","code":""},{"path":"http://www.shaunporwal.com/islet/reference/from_win_to_mac.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Title — from_win_to_mac","text":"","code":"from_win_to_mac(windows_path, mounted_drive_name)"},{"path":"http://www.shaunporwal.com/islet/reference/from_win_to_mac.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Title — from_win_to_mac","text":"windows_path Windows path converted Mac path mounted_drive_name Mounted drive included path","code":""},{"path":"http://www.shaunporwal.com/islet/reference/from_win_to_mac.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Title — from_win_to_mac","text":"Converted Mac path","code":""},{"path":"http://www.shaunporwal.com/islet/reference/from_win_to_mac.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Title — from_win_to_mac","text":"","code":"# Convert a Windows path to a Mac path with a mounted drive name of \"mydrive\" from_win_to_mac(\"C:\\\\Users\\\\myname\\\\Documents\\\\myfile.txt\", \"mydrive\") #> [1] \"/Volumes/mydriveC:/Users/myname/Documents/myfile.txt\"  # Convert a Windows path to a Mac path with a mounted drive name of \"Documents\" from_win_to_mac(\"C:\\\\Users\\\\myname\\\\Documents\\\\myfile.txt\", \"Documents\") #> [1] \"/Volumes/DocumentsC:/Users/myname/Documents/myfile.txt\""},{"path":"http://www.shaunporwal.com/islet/reference/get_sql.html","id":null,"dir":"Reference","previous_headings":"","what":"Read and Process an SQL File — get_sql","title":"Read and Process an SQL File — get_sql","text":"Reads SQL file line line, replaces tabs spaces, converts single-line SQL comments (--) C-style comments (/* ... */).","code":""},{"path":"http://www.shaunporwal.com/islet/reference/get_sql.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read and Process an SQL File — get_sql","text":"","code":"get_sql(filepath)"},{"path":"http://www.shaunporwal.com/islet/reference/get_sql.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read and Process an SQL File — get_sql","text":"filepath string representing path SQL file.","code":""},{"path":"http://www.shaunporwal.com/islet/reference/get_sql.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read and Process an SQL File — get_sql","text":"single string containing processed SQL code.","code":""},{"path":"http://www.shaunporwal.com/islet/reference/get_sql.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read and Process an SQL File — get_sql","text":"","code":"# Example usage: # sql_code <- get_sql(\"path/to/sql_file.sql\")"},{"path":"http://www.shaunporwal.com/islet/reference/islet-package.html","id":null,"dir":"Reference","previous_headings":"","what":"islet: Provides Data Pipelining Functions — islet-package","title":"islet: Provides Data Pipelining Functions — islet-package","text":"package houses data pipelining functions.","code":""},{"path":[]},{"path":"http://www.shaunporwal.com/islet/reference/islet-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"islet: Provides Data Pipelining Functions — islet-package","text":"Maintainer: Shaun P. Porwal shaun.Porwal@gmail.com","code":""},{"path":"http://www.shaunporwal.com/islet/reference/make_banner.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Banner for Code Separation/Organization — make_banner","title":"Create a Banner for Code Separation/Organization — make_banner","text":"Create Banner Code Separation/Organization","code":""},{"path":"http://www.shaunporwal.com/islet/reference/make_banner.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Banner for Code Separation/Organization — make_banner","text":"","code":"make_banner(str_to_banner, banner_chr = \"&\", output = TRUE)"},{"path":"http://www.shaunporwal.com/islet/reference/make_banner.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Banner for Code Separation/Organization — make_banner","text":"str_to_banner String Convert Banner banner_chr Banner Boundary Character output Boolean, TRUE output, FALSE Output","code":""},{"path":"http://www.shaunporwal.com/islet/reference/make_banner.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Banner for Code Separation/Organization — make_banner","text":"Invisible String","code":""},{"path":"http://www.shaunporwal.com/islet/reference/make_banner.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Banner for Code Separation/Organization — make_banner","text":"","code":"make_banner(str_to_banner = 'asdf', banner_chr = '&', output = TRUE) #> #&&&&&&&&&&&& #> #&&  asdf  && #> #&&&&&&&&&&&&"},{"path":"http://www.shaunporwal.com/islet/reference/parse_function.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse a Dataframe for Analysis — parse_function","title":"Parse a Dataframe for Analysis — parse_function","text":"Processes dataframe generate summaries numeric, factor, character, binary, date, data types. Supports year-based summaries group-specific outcomes. handle cases certain column types present dataset.","code":""},{"path":"http://www.shaunporwal.com/islet/reference/parse_function.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse a Dataframe for Analysis — parse_function","text":"","code":"parse_function(   parse_df,   suffix_term = \"\",   ind_outcomes = c(\"\"),   group_col = NULL,   add_years = FALSE )"},{"path":"http://www.shaunporwal.com/islet/reference/parse_function.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse a Dataframe for Analysis — parse_function","text":"parse_df Dataframe. Input dataframe parse analyze. suffix_term Character. Suffix append parsed column names (default: \"\"). ind_outcomes Character vector. Individual outcomes parsing group-specific summaries (default: \"\"). group_col Character. Column name representing grouping variable (default: NULL). add_years Logical. Include year-based summaries output (default: FALSE).","code":""},{"path":"http://www.shaunporwal.com/islet/reference/parse_function.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parse a Dataframe for Analysis — parse_function","text":"list dataframes summarizing input dataset. includes summaries column types present input data: date_df Summaries date columns (present). binary_df Summaries binary columns (present). char_df Summaries character columns (present). factor_df Summaries factor columns (present). summary_numeric Summaries numeric columns (present). group_df Summaries group specified outcomes (applicable).","code":""},{"path":"http://www.shaunporwal.com/islet/reference/read_raw_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Read and Clean Raw Data — read_raw_data","title":"Read and Clean Raw Data — read_raw_data","text":"function reads CSV file performs several cleaning steps: Optionally converts column names uppercase using janitor::clean_names. Attempts parse character columns dates ymd format. Optionally converts character columns uppercase parsed dates.","code":""},{"path":"http://www.shaunporwal.com/islet/reference/read_raw_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read and Clean Raw Data — read_raw_data","text":"","code":"read_raw_data(file, col_caps = TRUE, str_caps = TRUE)"},{"path":"http://www.shaunporwal.com/islet/reference/read_raw_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read and Clean Raw Data — read_raw_data","text":"file string specifying path CSV file read. col_caps Logical. Whether convert column names uppercase. Default TRUE. str_caps Logical. Whether convert string column values uppercase. Default TRUE.","code":""},{"path":"http://www.shaunporwal.com/islet/reference/read_raw_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read and Clean Raw Data — read_raw_data","text":"data frame cleaned column names data.","code":""},{"path":"http://www.shaunporwal.com/islet/reference/read_raw_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read and Clean Raw Data — read_raw_data","text":"","code":"if (FALSE) { # \\dontrun{   # Assuming 'data.csv' contains appropriate data   cleaned_data <- read_raw_data(\"data.csv\")   raw_data <- read_raw_data(\"data.csv\", col_caps = FALSE, str_caps = FALSE) } # }"},{"path":"http://www.shaunporwal.com/islet/reference/to_sql_query.html","id":null,"dir":"Reference","previous_headings":"","what":"Format text from SQL file into proper SQL query — to_sql_query","title":"Format text from SQL file into proper SQL query — to_sql_query","text":"Format text SQL file proper SQL query","code":""},{"path":"http://www.shaunporwal.com/islet/reference/to_sql_query.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format text from SQL file into proper SQL query — to_sql_query","text":"","code":"to_sql_query(filepath)"},{"path":"http://www.shaunporwal.com/islet/reference/to_sql_query.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format text from SQL file into proper SQL query — to_sql_query","text":"filepath Path SQL file","code":""},{"path":"http://www.shaunporwal.com/islet/reference/to_sql_query.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format text from SQL file into proper SQL query — to_sql_query","text":"SQL query string","code":""},{"path":"http://www.shaunporwal.com/islet/reference/to_sql_query.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Format text from SQL file into proper SQL query — to_sql_query","text":"","code":"# Path to the SQL file filepath <- system.file(\"extdata\", \"my_sql_file.sql\", package = \"my_package\")  # Call the function to read the SQL file and format it into a query to_sql_query(filepath) #> Warning: file(\"\") only supports open = \"w+\" and open = \"w+b\": using the former #> [1] \"\""}]
